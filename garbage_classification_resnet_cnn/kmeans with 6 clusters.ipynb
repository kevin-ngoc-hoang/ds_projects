{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f57edf44-f778-47ba-bedc-a9cff32855b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers, Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f9a7658-4104-4ad0-b19c-6dabf133d587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contains txt files\n",
    "path_data = r'C:\\Users\\hnkev\\Downloads\\W207 Final Project\\\\'\n",
    "\n",
    "label_dir = path_data + 'garbage_txt\\\\'\n",
    "# Contains img files\n",
    "image_dir = path_data + 'garbage_img\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7679d3c9-0748-4a49-b0cd-1f7b9929e326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\hnkev\\\\Downloads\\\\W207 Final Project\\\\\\\\garbage_txt\\\\'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72558791-429d-4a50-8af6-5ca4c3b43fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read train, validation, test split from txt files\n",
    "train_file = label_dir + 'one-indexed-files-notrash_train.txt'\n",
    "val_file   = label_dir + 'one-indexed-files-notrash_val.txt'\n",
    "test_file  = label_dir + 'one-indexed-files-notrash_test.txt'\n",
    "\n",
    "df_train = pd.read_csv(train_file, sep=' ', header=None, names=['path', 'label'])\n",
    "df_valid = pd.read_csv(val_file,   sep=' ', header=None, names=['path', 'label'])\n",
    "df_test  = pd.read_csv(test_file,   sep=' ', header=None, names=['path', 'label'])\n",
    "\n",
    "# Converts label id to name\n",
    "def label_id_to_name(id):\n",
    "  label_map = {1: 'glass', 2: 'paper', 3: 'cardboard', 4: 'plastic', 5: 'metal', 6: 'trash'}\n",
    "  return label_map[id]\n",
    "\n",
    "df_train['label'] = df_train['label'].apply(label_id_to_name)\n",
    "df_valid['label'] = df_valid['label'].apply(label_id_to_name)\n",
    "df_test['label'] = df_test['label'].apply(label_id_to_name)\n",
    "\n",
    "# Change file name to file path i.e. cardboard114.jpg\t to cardboard/cardboard114.jpg\t\n",
    "df_train.path = df_train.path.str.extract(r'([a-z]+)')[0] + \"\\\\\" + df_train.path\n",
    "df_valid.path = df_valid.path.str.extract(r'([a-z]+)')[0] + \"\\\\\" + df_valid.path\n",
    "df_test.path = df_test.path.str.extract(r'([a-z]+)')[0] + \"\\\\\" + df_test.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb8c428b-0bf5-42cd-8a90-6bb55cdfb24a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "paper        403\n",
       "glass        354\n",
       "plastic      347\n",
       "cardboard    287\n",
       "metal        286\n",
       "trash         91\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19c902aa-3d77-4f67-9b93-ebc8cf93446e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_list = []\n",
    "train_img_arr_list = []\n",
    "\n",
    "for suffix in list(df_train.path):\n",
    "    img = load_img(image_dir + suffix)\n",
    "    \n",
    "    train_img_list.append(img)\n",
    "    train_img_arr_list.append(img_to_array(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c959c7ec-3640-42c7-b0b3-67d17f38c496",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_img_flatten = []\n",
    "image_size = (224, 224)\n",
    "\n",
    "for img_arr in train_img_arr_list:\n",
    "    img = tf.image.resize(img_arr, size=image_size)\n",
    "    train_img_flatten.append(img.numpy().flatten())\n",
    "    \n",
    "X = np.array(train_img_flatten, dtype = 'int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "072d1dcd-e6b8-49ea-bdf6-6ebf9bc0ad6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hnkev\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1043: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 2048 or by setting the environment variable OMP_NUM_THREADS=7\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "n_clusters = 6\n",
    "random_state = 0  # makes sure you get the same results each time\n",
    "\n",
    "def fit_kmeans(X, n_clusters, random_state):\n",
    "  ## YOUR CODE HERE ## \n",
    "  model = MiniBatchKMeans(n_clusters=n_clusters,\n",
    "                 random_state=random_state,\n",
    "                 batch_size = 16384)\n",
    "  model.fit(X)\n",
    "  return model\n",
    "\n",
    "model = fit_kmeans(X, n_clusters, random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be1c4ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map_reverse = {'glass':0, 'paper':1, 'cardboard':2, 'plastic':3, 'metal':4, 'trash':5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "764bee19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Map the centroids to the corresponding values, \n",
    "#which are the most probable labels in the training set for the k means cluster labels\n",
    "\n",
    "label_nums = np.array([label_map_reverse[label] for label in df_train.label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "854edcfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1, 1: 3, 2: 0, 3: 2, 4: 1, 5: 2}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_labels = {}\n",
    "\n",
    "for i in np.unique(model.labels_):\n",
    "    index = np.where(model.labels_ == i, 1, 0)\n",
    "    num = np.bincount(label_nums[index == 1]).argmax()\n",
    "    reference_labels[i] = num\n",
    "\n",
    "reference_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47b01970",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_labels_verbal = {0:'paper', 1:'plastic', 2:'glass', 3:'cardboard', 4:'paper', 5:'cardboard'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5daf25bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_list = []\n",
    "test_img_arr_list = []\n",
    "\n",
    "for suffix in list(df_test.path):\n",
    "    img = load_img(image_dir + suffix)\n",
    "    \n",
    "    test_img_list.append(img)\n",
    "    test_img_arr_list.append(img_to_array(img))\n",
    "\n",
    "test_img_flatten = []\n",
    "image_size = (224, 224)\n",
    "\n",
    "for img_arr in test_img_arr_list:\n",
    "    img = tf.image.resize(img_arr, size=image_size)\n",
    "    test_img_flatten.append(img.numpy().flatten())\n",
    "    \n",
    "X_test = np.array(test_img_flatten, dtype = 'int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1fb7f107",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "22922673",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kmeans_test = df_test\n",
    "df_kmeans_test['kmeans_preds'] = [reference_labels_verbal[cluster] for cluster in test_preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c617559a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "      <th>kmeans_preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>paper\\paper70.jpg</td>\n",
       "      <td>paper</td>\n",
       "      <td>cardboard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>paper\\paper380.jpg</td>\n",
       "      <td>paper</td>\n",
       "      <td>glass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cardboard\\cardboard31.jpg</td>\n",
       "      <td>cardboard</td>\n",
       "      <td>cardboard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>glass\\glass12.jpg</td>\n",
       "      <td>glass</td>\n",
       "      <td>paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>paper\\paper169.jpg</td>\n",
       "      <td>paper</td>\n",
       "      <td>paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>metal\\metal389.jpg</td>\n",
       "      <td>metal</td>\n",
       "      <td>cardboard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>paper\\paper303.jpg</td>\n",
       "      <td>paper</td>\n",
       "      <td>plastic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>paper\\paper405.jpg</td>\n",
       "      <td>paper</td>\n",
       "      <td>glass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>paper\\paper465.jpg</td>\n",
       "      <td>paper</td>\n",
       "      <td>glass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>trash\\trash132.jpg</td>\n",
       "      <td>trash</td>\n",
       "      <td>plastic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>431 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          path      label kmeans_preds\n",
       "0            paper\\paper70.jpg      paper    cardboard\n",
       "1           paper\\paper380.jpg      paper        glass\n",
       "2    cardboard\\cardboard31.jpg  cardboard    cardboard\n",
       "3            glass\\glass12.jpg      glass        paper\n",
       "4           paper\\paper169.jpg      paper        paper\n",
       "..                         ...        ...          ...\n",
       "426         metal\\metal389.jpg      metal    cardboard\n",
       "427         paper\\paper303.jpg      paper      plastic\n",
       "428         paper\\paper405.jpg      paper        glass\n",
       "429         paper\\paper465.jpg      paper        glass\n",
       "430         trash\\trash132.jpg      trash      plastic\n",
       "\n",
       "[431 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_kmeans_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "605204de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3805104408352668"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans_6_test_acc = sum(df_test.label == df_kmeans_test.kmeans_preds)/len(df_test.label == df_kmeans_test.kmeans_preds)\n",
    "kmeans_6_test_acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
